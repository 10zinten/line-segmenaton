{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default double_tsek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from deskew import determine_skew\n",
    "import diff_match_patch as dmp_module\n",
    "from MTM import matchTemplates, drawBoxesOnRGB\n",
    "import numpy as np\n",
    "from openpecha.serializers import Serialize\n",
    "from tqdm import tqdm\n",
    "from xml.dom import minidom\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exxport\n",
    "class config:\n",
    "    # ocr_output paths\n",
    "    ocr_path = Path('/home/tenzin/ML/project/Esukhia/Google-OCR/archive')\n",
    "    # peydurma tengyur\n",
    "#     images_path = ocr_path/'images'/'W1PD95844'\n",
    "#     res_path = ocr_path/'output'/'W1PD95844'\n",
    "    # peydurma kangyur\n",
    "    images_path = ocr_path/'images'/'W1PD96682'\n",
    "    res_path = ocr_path/'output'/'W1PD96682'\n",
    "    \n",
    "    # peydurma path\n",
    "    peydurma_path = Path('data/peydurma')\n",
    "    template_path = peydurma_path/'templates'\n",
    "    peydurma_meta_fn = peydurma_path/'tengyur-peydurma-bdrc.xml'\n",
    "    \n",
    "    # dergey opf path\n",
    "    op_path = Path('/home/tenzin/ML/project/Esukhia/openpecha-user/.openpecha/data/')\n",
    "    tengyur_opf = op_path/'P000002/P000002.opf'\n",
    "    kangyur_opf = op_path/'P000001/P000001.opf'\n",
    "    \n",
    "    # output_path\n",
    "    output_path = peydurma_path/'output'\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    output_tmp_path = output_path/'tmp'\n",
    "    output_tmp_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # annotation\n",
    "    double_tsek_sym = '$'\n",
    "    tsek = '་'\n",
    "    \n",
    "    # image\n",
    "    img_size = (3969, 2641)\n",
    "    \n",
    "    # dev\n",
    "    debug = False\n",
    "    \n",
    "dmp = dmp_module.diff_match_patch()\n",
    "dmp.Diff_Timeout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def plot(img, cmap=None, sz=(10, 10), axis=False):\n",
    "    plt.figure(figsize=sz)\n",
    "    plt.grid(True)\n",
    "    if not axis:\n",
    "        plt.axis('off')\n",
    "        plt.grid(False)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_box(coord):\n",
    "#     x, y, w, h = coord\n",
    "#     x2, y2 = x+w, y+h\n",
    "#     return x, y, x2, y2\n",
    "\n",
    "\n",
    "# def create_template(img_path, coord, t_fn=None, template=False):\n",
    "#     img = cv2.imread(str(img_path))\n",
    "#     print(img.shape)\n",
    "#     if not template:\n",
    "#         img = cv2.resize(img, (config.img_size[1], config.img_size[0]))\n",
    "#     img_copy = img.copy()\n",
    "#     x1, y1, x2, y2 = to_box(coord)\n",
    "#     cv2.rectangle(img_copy, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "    \n",
    "#     x, y, w, h = coord\n",
    "#     template = img[y:y+h, x:x+w]\n",
    "#     plot(template)\n",
    "#     plot(img_copy, sz=(25, 25))\n",
    "\n",
    "#     if t_fn:\n",
    "#         cv2.imwrite(str(t_fn), template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coord = (2139, 1282, 18, 135) # (x, y, w, h)\n",
    "# create_template('data/test-mantra.jpg', coord, t_fn=config.template_path/'double_tsek_02.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = config.images_path/'I1PD95846'/'I1PD958460141.jpg'\n",
    "# coord = (1162, 1910, 13, 135) # (x, y, w, h)\n",
    "# create_template(img_path, coord, t_fn=config.template_path/'double_tsek_03.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure OpenCV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #image = cv2.imread('data/test.jpeg')\n",
    "# image = cv2.imread('data/test_diff_size.jpeg')\n",
    "# image = imutils.resize(image, height=3969, width=2645)\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# blur = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "# thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# # Create rectangular structuring element and dilate\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "# dilate = cv2.dilate(thresh, kernel, iterations=7)\n",
    "# plot(dilate, cmap='gray', sz=(25, 25))\n",
    "\n",
    "# # Find contours and draw rectangle\n",
    "# cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "# for c in cnts:\n",
    "#     x,y,w,h = cv2.boundingRect(c)\n",
    "#     cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "\n",
    "# plot(image, sz=(25, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Skew Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def image_deskew2(image, show_diff=False):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     gray = cv2.bitwise_not(gray)\n",
    "#     thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "#     coords = np.column_stack(np.where(thresh > 2))\n",
    "#     angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "#     if angle < -45:\n",
    "#         angle = -(90 + angle)\n",
    "#     else:\n",
    "#         angle = -angle\n",
    "\n",
    "#     # rotate the image to deskew it\n",
    "#     (h, w) = image.shape[:2]\n",
    "#     center = (w // 2, h // 2)\n",
    "#     M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "#     rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "#     print(f'[INFO] Image dskewed by {angle:.3} angles')\n",
    "    \n",
    "#     if show_diff:\n",
    "#         plot(image, sz=(15, 15), axis=True)\n",
    "#         plot(rotated, sz=(15, 15), axis=True)\n",
    "        \n",
    "#     return rotated\n",
    "\n",
    "def image_deskew(image, show_diff=False):\n",
    "    def rotate(image, angle, background):\n",
    "        old_width, old_height = image.shape[:2]\n",
    "        angle_radian = math.radians(angle)\n",
    "        width = abs(np.sin(angle_radian) * old_height) + abs(np.cos(angle_radian) * old_width)\n",
    "        height = abs(np.sin(angle_radian) * old_width) + abs(np.cos(angle_radian) * old_height)\n",
    "\n",
    "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "        rot_mat[1, 2] += (width - old_width) / 2\n",
    "        rot_mat[0, 2] += (height - old_height) / 2\n",
    "        return cv2.warpAffine(image, rot_mat, (int(round(height)), int(round(width))), borderValue=background)\n",
    "    \n",
    "    if isinstance(image, (str, Path)):\n",
    "        image = cv2.imread(str(image))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    angle = determine_skew(gray)\n",
    "    backgroud = tuple([int(x) for x in image[10][10]])\n",
    "    rotated = rotate(image, angle, backgroud)\n",
    "    \n",
    "    print(f'[INFO] Image dskewed by {angle:.4} angles')\n",
    "    \n",
    "    if show_diff:\n",
    "        plot(image, sz=(15, 15), axis=True)\n",
    "        plot(rotated, sz=(15, 15), axis=True)\n",
    "        \n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# _ = image_deskew(cv2.imread('data/peydurma/test-set/white_skewed_01.jpg'), show_diff=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# _ = image_deskew(cv2.imread('data/peydurma/test-set/white_skewed_dtsek_01.jpg'), show_diff=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sorted_matches(matches):\n",
    "#     h_sorted_match = []\n",
    "#     for x, y in matches:\n",
    "#         found_group = False\n",
    "#         if h_sorted_match:\n",
    "#             for h_list in h_sorted_match:\n",
    "#                 if abs(y-h_list[0][1]) < 5:\n",
    "#                     h_list.append((x, y))\n",
    "#                     found_group = True\n",
    "#         else:\n",
    "#             h_sorted_match.append([(x, y)])\n",
    "#             found_group = True\n",
    "\n",
    "#         if not found_group:\n",
    "#             h_sorted_match.append([(x, y)])\n",
    "        \n",
    "#     full_sorted_match = []\n",
    "#     for h_list in h_sorted_match:\n",
    "#         full_sorted_match.append(sorted(h_list, key=lambda x: x[0]))\n",
    "        \n",
    "#     return sum(full_sorted_match, [])\n",
    "    \n",
    "\n",
    "# def remove_dup_match(match_locations):\n",
    "#     cleaned_match = []\n",
    "#     prev_x, prev_y = 0, 0\n",
    "#     th = 2\n",
    "#     for x, y in sorted_matches(zip(match_locations[1], match_locations[0])):\n",
    "#         if abs(x-prev_x) < 5 and abs(y-prev_y) < 5: continue\n",
    "#         cleaned_match.append((x, y))\n",
    "#         prev_x, prev_y = x, y\n",
    "#     return cleaned_match\n",
    "\n",
    "\n",
    "# def template_match(img, templates):\n",
    "#     # create edged image\n",
    "#     if isinstance(img, str):\n",
    "#         img = cv2.imread(img)\n",
    "#     if size:\n",
    "#         img = imutils.resize(img, height=config.img_size[0], width=config.img_size[1])\n",
    "#     print('Image size:', img.shape)\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     #plot(gray, cmap='gray', sz=(50, 50))\n",
    "#     edged = cv2.Canny(gray, 100, 600)\n",
    "#     #plot(edged, cmap='gray', sz=(50, 50))\n",
    "    \n",
    "#     output = defaultdict(list)\n",
    "#     clone = img.copy()\n",
    "#     for template_ in templates:\n",
    "#         t_type, template, th, data = template_\n",
    "        \n",
    "#         # template matching\n",
    "#         result = cv2.matchTemplate(edged, template, cv2.TM_CCOEFF)\n",
    "#         min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "#         max_thresh = max_val * th\n",
    "#         match_locations = np.where(result>=max_thresh)\n",
    "#         cleaned_match_locations = remove_dup_match(match_locations)\n",
    "        \n",
    "#         # Plot\n",
    "#         w, h = template.shape[::-1]\n",
    "#         for (x, y) in cleaned_match_locations:\n",
    "#             output[t_type].append((x, y))\n",
    "#             cv2.rectangle(clone, (x, y), (x+w, y+h), [0,0,255], 2)\n",
    "    \n",
    "#         print(f'No. {t_type} detected: {len(output[t_type])}')\n",
    "\n",
    "#     plot(clone, cmap='gray', sz=(25, 25))\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# templates = [\n",
    "#     ('rectangle', rect_template, 0.9, {}),\n",
    "#     #('circle', cir_template, 0.7, {'radius': radius})\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = template_match('data/test-mantra.jpg', templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Template-Matching Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_templates(path):\n",
    "    templates = []\n",
    "    for p in Path(path).iterdir():\n",
    "        if not p.name.endswith('.png'): continue\n",
    "        templates.append((p.stem, cv2.imread(str(p))))\n",
    "    return templates\n",
    "\n",
    "def mtm(image, templates, show=False, th=0.9):\n",
    "    if isinstance(image, (str, Path)):\n",
    "        image = cv2.imread(str(image))\n",
    "    matches = []\n",
    "    try:\n",
    "        hits = matchTemplates(templates, image, score_threshold=th, method=cv2.TM_CCOEFF_NORMED, maxOverlap=0.3)\n",
    "        for x, y, w, h in list(hits['BBox']):\n",
    "            matches.append([x, y, x+w, y+h])\n",
    "        if show: image = drawBoxesOnRGB(image, hits, boxThickness=5, boxColor=(255,0,0))\n",
    "    except KeyError as ex:\n",
    "        if ex.args[0] == 'Score':\n",
    "            print('\\t- double tsek not found !')\n",
    "            return matches\n",
    "\n",
    "    print(f'\\t- no. of double tsek detected: {len(matches)}')    \n",
    "    if show:\n",
    "        plot(image, sz=(15, 15))\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates = get_templates(config.template_path); len(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_output = mtm('data/test.jpeg', templates, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtm('data/test-mantra.jpg', templates, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtm('data/test-02.jpeg', templates, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtm('data/test_diff_size.jpeg', templates, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtm('data/test-03.jpg', templates, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on actual Peydurma Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtm('data/peydurma-05.jpg', templates, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtm('data/peydurma/test-set/yellow_01.jpg', templates, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtm('data/peydurma/test-set/yellow_02.jpg', templates, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewed_output = mtm('data/peydurma/test-set/white_skewed_dtsek_01.jpg', templates, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deskewed_img = image_deskew(config.images_path/'I1PD95846'/'I1PD958460141.jpg')\n",
    "# plot(deskewed_img)\n",
    "#mtm(config.images_path/'I1PD95846'/'I1PD958460141.jpg', templates, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find reinsertion span\n",
    "find line number and char location of double tsek\n",
    "- input: ocr_boxes, match_loc\n",
    "- output: line number and char index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import vision\n",
    "# from google.cloud.vision import types\n",
    "# from google.protobuf.json_format import MessageToJson\n",
    "\n",
    "# vision_client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ocr(image, path):\n",
    "#     path = Path(path)\n",
    "#     res_fn = path.parent/f'{path.stem}.json'\n",
    "#     if res_fn.is_file():\n",
    "#         response = json.load(res_fn.open())\n",
    "#     else:\n",
    "#         if isinstance(image, (str, Path)):\n",
    "#             with open(path, 'rb') as image_file:\n",
    "#                 content = image_file.read()\n",
    "#         else:\n",
    "#             content = image\n",
    "#         image = types.Image(content=content)\n",
    "#         response_pb = vision_client.document_text_detection(image=image)\n",
    "#         response = eval(MessageToJson(response_pb))\n",
    "#         json.dump(response, res_fn.open('w'))\n",
    "#     return response\n",
    "\n",
    "# convert image array to image bytes\n",
    "# success, encoded_image = cv2.imencode('.jpg', image)\n",
    "# image_bytes = encoded_image.tobytes()\n",
    "# response = ocr(image_bytes, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get OCR output\n",
    "- unzip ocr output and read the response json\n",
    "- resize the box w.r.t config.img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ocr_output(path):\n",
    "    imagegroup, img_fn = path.parts[-2:]\n",
    "    res_fn = config.res_path/imagegroup/f'{img_fn.split(\".\")[0]}.json.gz'\n",
    "    return json.load(gzip.open(str(res_fn), 'rb'))\n",
    "\n",
    "def get_symbol(response):\n",
    "    for page in response['fullTextAnnotation']['pages']:\n",
    "        for block in page['blocks']:\n",
    "            for paragraph in block['paragraphs']:\n",
    "                for word in paragraph['words']:\n",
    "                    for symbol in word['symbols']:\n",
    "                        char = symbol['text']\n",
    "                        v = symbol['boundingBox']['vertices']\n",
    "                        box = [v[0]['x'], v[0]['y'], v[2]['x'], v[2]['y']]\n",
    "                        yield char, box\n",
    "\n",
    "def get_full_text_annotations(response):\n",
    "    boxes, text = [], ''\n",
    "    for char, box in get_symbol(response):\n",
    "        text += char\n",
    "        boxes.append(box)\n",
    "    return boxes, text\n",
    "\n",
    "def resize_boxes(boxes, old_size):\n",
    "    \"`boxes` are in top-right and bottom-left coord system.\"\n",
    "    h, w = old_size[:2]\n",
    "    h_scale = config.img_size[0]/h\n",
    "    w_scale = config.img_size[1]/w\n",
    "    result = []\n",
    "    for box in boxes:\n",
    "        # adjust the box\n",
    "        box[0] *= w_scale\n",
    "        box[1] *= h_scale\n",
    "        box[2] *= w_scale\n",
    "        box[3] *= h_scale\n",
    "        box = list(map(int, box))\n",
    "        result.append(box)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxes(img, boxes, show=True, color=[0,0,255]):\n",
    "    for x1, y1, x2, y2 in boxes[0]:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "    if len(boxes) > 1:\n",
    "        for x1, y1, x2, y2 in boxes[1]:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), [255,0,0], 5)\n",
    "    if show: plot(img, sz=(25, 25))\n",
    "    else: return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_resize_boxes(image_path):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    old_size = image.shape\n",
    "    image = cv2.resize(image, (config.img_size[1], config.img_size[0]))\n",
    "    response = get_ocr_output(image_path)\n",
    "    boxes, text = get_full_text_annotations(response)\n",
    "    print(text)\n",
    "    boxes = resize_boxes(boxes, old_size)\n",
    "    plot_boxes(image, [boxes, []])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_resize_boxes(config.images_path/'I1PD95846'/'I1PD958460142.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_resize_boxes(config.images_path/'I1PD95846'/'I1PD958460141.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get context of Double Tsek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cls_box_into_line(boxes, th=20):\n",
    "    lines = []\n",
    "    line = []\n",
    "    prev_y1 = boxes[0][1]\n",
    "    for box in boxes:\n",
    "        if abs(box[1] - prev_y1) < th:\n",
    "            line.append(box)\n",
    "        else:\n",
    "            lines.append(line)\n",
    "            line = []\n",
    "            line.append(box)\n",
    "        prev_y1 = box[1]\n",
    "    else:\n",
    "        if line: lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_box_into_line(image_path):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    old_size = image.shape\n",
    "    image = cv2.resize(image, (config.img_size[1], config.img_size[0]))\n",
    "    response = get_ocr_output(image_path)\n",
    "    boxes, text = get_full_text_annotations(response)\n",
    "    boxes = resize_boxes(boxes, old_size)\n",
    "    boxe_lines = cls_box_into_line(boxes)\n",
    "    \n",
    "    for box_line in boxe_lines:\n",
    "        r, g, b = map(int, np.random.choice(range(256), size=3))\n",
    "        image = plot_boxes(image, [box_line], show=False, color=(r,g,b))\n",
    "    plot(image, sz=(25, 25))\n",
    "    \n",
    "#test_box_into_line(config.images_path/'I1PD95846'/'I1PD958460048.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_double_tsek_bf(matched_box, boxes, th=20):\n",
    "    box_lines = cls_box_into_line(boxes)\n",
    "    pos = 0\n",
    "    prev_x1 = 0\n",
    "    for box_line in box_lines:\n",
    "        if abs(matched_box[1] - box_line[0][1]) < th:\n",
    "            for i, box in enumerate(box_line):\n",
    "                if matched_box[0] > prev_x1 and matched_box[0] < box[0]:\n",
    "                    pos += i-1\n",
    "                    return pos\n",
    "        pos += len(box_line)\n",
    "        \n",
    "\n",
    "def compute_iou(box_arr1, box_arr2):\n",
    "    x11, y11, x12, y12 = np.split(box_arr1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = np.split(box_arr2, 4, axis=1)\n",
    "    \n",
    "    xA = np.maximum(x11, np.transpose(x21))\n",
    "    yA = np.maximum(y11, np.transpose(y21))\n",
    "    xB = np.minimum(x12, np.transpose(x22))\n",
    "    yB = np.minimum(y12, np.transpose(y22))\n",
    "    interArea = np.maximum((xB - xA + 1), 0) * np.maximum((yB - yA + 1), 0)\n",
    "    boxAArea = (x12 - x11 + 1) * (y12 - y11 + 1)\n",
    "    boxBArea = (x22 - x21 + 1) * (y22 - y21 + 1)\n",
    "    iou = interArea / (boxAArea + np.transpose(boxBArea) - interArea)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "\n",
    "def get_double_tsek_idx(image_path, templates, deskew=False, show_boxes=False):\n",
    "    # load, deskew and resize the image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    old_size = image.shape\n",
    "    if deskew: image = image_deskew(image)\n",
    "    image = image = cv2.resize(image, (config.img_size[1], config.img_size[0]))\n",
    "    \n",
    "    # find the double tsek boxes\n",
    "    matches = mtm(image, templates)\n",
    "    \n",
    "    # Get ocr boxes\n",
    "    response = get_ocr_output(image_path)\n",
    "    boxes, text = get_full_text_annotations(response)\n",
    "    if not matches: return [], text\n",
    "    boxes = resize_boxes(boxes, old_size)\n",
    "    \n",
    "    # find double tsek char index\n",
    "    iou_matrix = compute_iou(np.array(matches), np.array(boxes))\n",
    "    if show_boxes: plot_boxes(image, [boxes, matches])\n",
    "    idxs = list(np.argmax(iou_matrix, axis=1))\n",
    "    if 0 in idxs:\n",
    "        undetected_box_idx = idxs.index(0)\n",
    "        undetected_box_char_idx = find_double_tsek_bf(matches[undetected_box_idx], boxes)\n",
    "        idxs[undetected_box_idx] = undetected_box_char_idx\n",
    "    idxs.sort()\n",
    "    return idxs, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_get_double_tsek_idx(image_path):\n",
    "    idxs, text = get_double_tsek_idx(image_path, templates, show_boxes=True)\n",
    "    print(idxs)\n",
    "    for cc in idxs:\n",
    "        print(text[cc-10:cc], text[cc], text[cc+1: cc+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_get_double_tsek_idx(config.images_path/'I1PD95846'/'I1PD958460047.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_get_double_tsek_idx(config.images_path/'I1PD95846'/'I1PD958460043.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_get_double_tsek_idx(config.images_path/'I1PD95846'/'I1PD958460048.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_whitespaces(text):\n",
    "    result = ''\n",
    "    for chunk in text.split('།'):\n",
    "        if chunk:\n",
    "            result += chunk + '། '\n",
    "        else:\n",
    "            result += '།'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_str = '།ལས་བརྒྱ་ཐམ་པ་པ།༄༅།།རྒྱ་གར་སྐད་དུ།ཀརྨ་ཤ་ཏ་ཀ།བོད་སྐད་དུ།ལས་བརྒྱ་ཐམ་པ་པོ།བམ་པོ་དང་པོ།ཐམས་ཅད་མཁྱེན་པ་ལ་ཕྱག་འཚལ་ལོ།།གང་ལས་འཇིག་རྟེན་བླ་མ་བདེ་གཤེགས་ཐོས་པའི་སྒོ་ནས་རབ་སྙན་བརྟན་པའི་གསུང་་་་ལྡན་གྱིས།།སེམས་ཅན་རྣམས་ལ་ཕན་པ་འབའ་ཞིག་བཞེད་ཕྱིར་བཤད་པ་རྣམ་པ་སྣ་ཚོགས་རང་ཉིད་ཀྱིས།།ལོག་པར་ལྟ་བའི་མུན་ནག་ཆེན་པོ་ཐིབས་པོར་$འཐོམས་ཤིངའཁྲུགས་པ་རྣམས་ལ་རབ་གསུངས་པ།།་$དེ་ཡི་མིང་ནི་ལས་རྣམ་བརྒྱ་པ་ཞེས་བྱ་ཡོངས་སུ་ཚང་བ་བདག་གིས་བཤད་ཀྱིས་ཉོན།།སྤྱི་སྡོམ་ནི༑ཁྱི་མོ་དང་ནི་ཤིང་རྟ་དང་།།ཀ་ཙང་ཀ་ལ་བྱམས་མི་སྡུག།བྱ་དང་འཕྱེ་བོ་གང་པོ་དང་།།བུ་རྣམས་དང་ནི་བརྒྱ་བྱིན་ནོ།།སྡོམ་ནི།ཁྱི་མོ་མིག་ཆུང་ལ་རྫོགས་བྱེད་དང་།།སྒྱུར་གཉིས་འཆར་ཀ་རྒྱལ་མཚན་དང༌།།བདེ་བྱེད་མ་དང་ནོར་བུའི་འོད།།སྣ་མའི་མེ་ཏོག་ང་བྱིན་དང༌།།འདུས་མོ་དང་ནི་ཚེམ་བུ་མདོ་སྡེ།ཧ་མཁན༑།ཁྱི་མོ་ཞེས་བྱ་བ་ནི།གླེང་$གཞི་མཉན་དུ་ཡོད་པ་ན་བཞུགས་ཏེ།དེའི་ཚེ་མཉན་དུ་ཡོད་པ་ནི།ཁྱིམ་བདག་ཕྱུག་ཅིང་ནོར་མང་ལ་ལོངས་སྤྱོད་ཆེ་བ་ཡོངས་ས'\n",
    "# put_whitespaces(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def rm_running_head(text):\n",
    "    r_head_end_idx = text.find('༡')\n",
    "    if r_head_end_idx >= 0  and r_head_end_idx < 500:\n",
    "        return text[r_head_end_idx+1:]\n",
    "    else:\n",
    "        return text[text.find('།')+1:]\n",
    "\n",
    "def rm_noise(text):\n",
    "    'remove numbers and etc'\n",
    "    text = re.sub(f'\\d+', '', text)\n",
    "    for r in ['=', '|', '“', '”', ']', '）', ')', '》', '>', '©', '–', '-', '༸', ('་ི', '་')]:\n",
    "        if isinstance(r, tuple):\n",
    "            text = text.replace(r[0], r[1])\n",
    "        else:\n",
    "            text = text.replace(r, '')\n",
    "    return text\n",
    "\n",
    "def postprocess(text):\n",
    "    text = rm_running_head(text)\n",
    "    text = rm_noise(text)\n",
    "    for f, t in [('$་','་$'), ('$།', '།$'), ('།་$', '།$')]:\n",
    "        text = text.replace(f, t)\n",
    "    text = put_whitespaces(text)\n",
    "    return text\n",
    "\n",
    "def str_insert(text, idx, char):\n",
    "    text = text[:idx] + char + text[idx:]\n",
    "    return text\n",
    "\n",
    "def add_double_tsek(text, idxs):\n",
    "    for i, idx in enumerate(idxs):\n",
    "        text = str_insert(text, idx+i, config.double_tsek_sym)\n",
    "    return text\n",
    "\n",
    "def get_double_tsek_text(text_id, path, start, end, engine):\n",
    "    ann_text_fn = config.output_tmp_path/f'{text_id}-peydurma-ann_text.txt'\n",
    "    if ann_text_fn.is_file():\n",
    "        ann_text = ann_text_fn.read_text()\n",
    "        if engine == 'diff':\n",
    "            return '', ann_text\n",
    "        base_text = ann_text.replace(config.double_tsek_sym, '')\n",
    "        return base_text, ann_text\n",
    "    ann_text = ''\n",
    "    for i, path in enumerate(sorted((path).iterdir()), 1):\n",
    "        if i <  start: continue\n",
    "        if i > end: break\n",
    "        print(f'[INFO] {i+1} - Processing {path.name} ...')\n",
    "        idxs, text = get_double_tsek_idx(path, templates)\n",
    "        ann_text += f'\\n\\n{path.name}' if config.debug else \"\"\n",
    "        ann_text += postprocess(add_double_tsek(text, idxs))\n",
    "    ann_text_fn.write_text(ann_text)\n",
    "    return base_text, ann_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.debug = True\n",
    "# base_text, ann_text = get_double_tsek_text('T340', config.images_path/'I1PD95846', 0, 0)\n",
    "# print(ann_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Annotations\n",
    "\n",
    "Steps:\n",
    "1. Paser peydurm-tengyur text index\n",
    "1. Map peydurma-tengyur text-id to dergey-tengyur text-id\n",
    "1. Extract corresponding dergey-tengyur text\n",
    "1. Extract double-tsek from peyduma-tengyur text\n",
    "1. Create dmp patch of double tsek\n",
    "1. Apply the dmp patch to dergey-tengyur\n",
    "1. Parse the dobule-tsek from dergey-tengyur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parser peydurma tengyur text index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_span(node):\n",
    "    vol, span = '', []\n",
    "    for loc in node.getElementsByTagName('outline:location'):\n",
    "        vol = int(loc.attributes['vol'].value)\n",
    "        span.append(int(loc.attributes['page'].value))\n",
    "    if not vol:\n",
    "        return\n",
    "    return {vol: {'start': min(span), 'end': max(span)}}\n",
    "\n",
    "def clean_text_id(text_id):\n",
    "    cats = '  abcd'\n",
    "    text_id = text_id.strip()\n",
    "    if text_id == '00':\n",
    "        return\n",
    "    elif '-' in text_id:\n",
    "        id_, cat = text_id.split('-')\n",
    "        if len(cat) > 1: return\n",
    "        return f'{id_}{cats[int(cat.strip())]}'\n",
    "    elif ';' in text_id:\n",
    "        return text_id.split(';')[0].strip()\n",
    "    else:\n",
    "        return text_id      \n",
    "\n",
    "def get_toh(fn):\n",
    "    maps = defaultdict(list)\n",
    "    dom = minidom.parse(str(fn))\n",
    "    for node in dom.getElementsByTagName('outline:node'):\n",
    "        if node.attributes['type'].value != \"text\": continue\n",
    "        for desc_node in node.getElementsByTagName('outline:description'):\n",
    "            attrs = desc_node.attributes\n",
    "            if 'type' in attrs and attrs['type'].value == \"toh\":\n",
    "                desc_childnodes = desc_node.childNodes\n",
    "                if not desc_childnodes: break\n",
    "                text_id = clean_text_id(desc_childnodes[0].data)\n",
    "                if not text_id: break\n",
    "                maps[text_id].append(get_text_span(node))\n",
    "                break\n",
    "    return maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# toh = get_toh(config.peydurma_meta_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Map peydurma toh to dergey text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def map_text_id(text_id, is_kangyur=False):\n",
    "    if is_kangyur:\n",
    "        return f'T{text_id}'\n",
    "    else:\n",
    "        return f'D{text_id}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract corresponding dergey-tengyur text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_index_layer(path):\n",
    "    index_layer = yaml.safe_load((path/'index.yml').open())\n",
    "    return index_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_layer = get_index_layer(config.tengyur_opf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_base_text(text_id, opf_path, index_layer):\n",
    "    serializer = Serialize(opf_path, text_id=text_id, index_layer=index_layer)\n",
    "    #base_text = ''.join(serializer.get_text_base_layer().values())\n",
    "    base_text = list(serializer.get_text_base_layer().values())[0]\n",
    "    return base_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_text = get_base_text('D1109', config.tengyur_opf, index_layer)\n",
    "# base_text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract double-tsek from peyduma-tengyur text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.debug = False\n",
    "# peydurma_base_text, peydurma_ann_text = get_double_tsek_text(config.images_path/'I1PD95846')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(peydurma_ann_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Transfer annotation with patchs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_anns_with_patch(base_text, src_text, dest_text):\n",
    "    \"Apply patches computed from `src_text` to `dest_text` on `base_text\"\n",
    "    diffs = dmp.diff_main(src_text, dest_text)\n",
    "    patches = dmp.patch_make(src_text, diffs)\n",
    "    ann_text = dmp.patch_apply(patches, base_text)[0]\n",
    "    double_tsek_idxs = parse_double_tsek(ann_text)\n",
    "    print(f'\\t- Transferred {len(double_tsek_idxs)} out of {len(patches)}')\n",
    "    return double_tsek_idxs, ann_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Transfer annotations with diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_anns_with_diff(base_text, dest_text):\n",
    "    ann_text = ''\n",
    "    for diff in tqdm(dmp.diff_main(base_text, dest_text, checklines=False)):\n",
    "        if diff[0] == 1:\n",
    "            if diff[1] == config.double_tsek_sym:\n",
    "                ann_text += diff[1]\n",
    "            elif config.double_tsek_sym in diff[1]:\n",
    "                ann_text += '$$'\n",
    "        else:\n",
    "            ann_text += diff[1]\n",
    "    double_tsek_idxs = parse_double_tsek(ann_text)\n",
    "    print(f'\\t- Transferred {len(double_tsek_idxs)} out of {dest_text.count(config.double_tsek_sym)}')\n",
    "    return double_tsek_idxs, ann_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Parse the double-tsek from dergey-tengyur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_double_tsek(text):\n",
    "    #base_text = ''\n",
    "    double_tsek_idxs = []\n",
    "    base_char_idx = 0\n",
    "    for c in text:\n",
    "        if c == config.double_tsek_sym:\n",
    "            double_tsek_idxs.append(base_char_idx)\n",
    "            continue\n",
    "        #base_text += c\n",
    "        base_char_idx += 1\n",
    "    return double_tsek_idxs#, base_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pedurma_ann_text = 'ལས་བརྒྱ་ཐམ་པ་པ། ༄༅། །རྒྱ་གར་སྐད་དུ། ཀརྨ་ཤ་ཏ་ཀ། བོད་སྐད་དུ། ལས་བརྒྱ་ཐམ་པ་པོ། བམ་པོ་དང་པོ། ཐམས་ཅད་མཁྱེན་པ་ལ་ཕྱག་འཚལ་ལོ། །གང་ལས་འཇིག་རྟེན་བླ་མ་བདེ་གཤེགས་ཐོས་པའི་སྒོ་ནས་རབ་སྙན་བརྟན་པའི་གསུང་་་་ལྡན་གྱིས། །སེམས་ཅན་རྣམས་ལ་ཕན་པ་འབའ་ཞིག་བཞེད་ཕྱིར་བཤད་པ་རྣམ་པ་སྣ་ཚོགས་རང་ཉིད་ཀྱིས། །ལོག་པར་ལྟ་བའི་མུན་ནག་ཆེན་པོ་ཐིབས་པོར་$འཐོམས་ཤིངའཁྲུགས་པ་རྣམས་ལ་རབ་གསུངས་པ། །$དེ་ཡི་མིང་ནི་ལས་རྣམ་བརྒྱ་པ་ཞེས་བྱ་ཡོངས་སུ་ཚང་བ་བདག་གིས་བཤད་ཀྱིས་ཉོན། །སྤྱི་སྡོམ་ནི༑ཁྱི་མོ་དང་ནི་ཤིང་རྟ་དང་། །ཀ་ཙང་ཀ་ལ་བྱམས་མི་སྡུག། བྱ་དང་འཕྱེ་བོ་གང་པོ་དང་། །བུ་རྣམས་དང་ནི་བརྒྱ་བྱིན་ནོ། །སྡོམ་ནི།'\n",
    "# derge_text = '༄༅༅། །རྒྱ་གར་སྐད་དུ། ཀརྨ་ཤ་ཏ་ཀ། བོད་སྐད་དུ། ལས་བརྒྱ་ཐམ་པ་པ། བམ་པོ་དང་པོ། ཐམས་ཅད་མཁྱེན་པ་ལ་ཕྱག་འཚལ་ལོ། །གང་ལས་འཇིག་རྟེན་བླ་མ་བདེ་གཤེགས་ཐོས་པའི་སྒོ་ནས་རབ་སྙན་བརྟན་པའི་གསུང་ལྡན་གྱིས། །སེམས་ཅན་རྣམས་ལ་ཕན་པ་འབའ་ཞིག་བཞེད་ཕྱིར་བཤད་པ་རྣམ་པ་སྣ་ཚོགས་རང་ཉིད་ཀྱིས། །ལོག་པར་ལྟ་བའི་མུན་ནག་ཆེན་པོ་ཐིབས་པོར་འཐོམས་ཤིང་འཁྲུགས་པ་རྣམས་ལ་རབ་གསུངས་པ། །དེ་ཡི་མིང་ནི་ལས་རྣམ་བརྒྱ་པ་ཞེས་བྱ་ཡོངས་སུ་ཚང་བ་བདག་གིས་བཤད་ཀྱིས་ཉོན། །སྤྱི་སྡོམ་ནི། ཁྱི་མོ་དང་ནི་ཤིང་རྟ་དང་། །ཀ་ཙང་ཀ་ལ་བྱམས་མི་སྡུག །བྱ་དང་འཕྱེ་བོ་གང་པོ་དང་། །བུ་རྣམས་དང་ནི་བརྒྱ་བྱིན་ནོ། །སྡོམ་ནི། ཁྱི་མོ་མིག་ཆུང་'\n",
    "# transfer_anns_with_diff(derge_text, pedurma_ann_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(text_id, p_vol_path, opf_path, index_layer, start=1, end=float('inf'), replace=False, engine='diff'):\n",
    "    print(f'[INFO] Transferring double tsek for {text_id}')\n",
    "    out_idxs_fn = config.output_path/f'{text_id}.txt'\n",
    "    ann_text_fn = config.output_path/f'{text_id}-ann_text.txt'\n",
    "    if not out_idxs_fn.is_file() or replace:\n",
    "        base_text = get_base_text(text_id, opf_path, index_layer)\n",
    "        p_base_text, p_ann_text = get_double_tsek_text(text_id, p_vol_path, start, end, engine)\n",
    "        if engine == 'diff':\n",
    "            double_tsek_idxs, ann_text = transfer_anns_with_diff(base_text, p_ann_text)\n",
    "        elif engine == 'patch':\n",
    "            double_tsek_idxs, ann_text = transfer_anns_with_patch(base_text, p_base_text, p_ann_text)\n",
    "\n",
    "        out_idxs_fn.write_text('\\n'.join(map(str, double_tsek_idxs)))\n",
    "        ann_text_fn.write_text(ann_text)\n",
    "    print(f'[INFO] Double tsek indices are save at {config.output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_layer = get_index_layer(config.kangyur_opf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Transferring double tsek for T340\n"
     ]
    }
   ],
   "source": [
    "run('T340',\n",
    "    config.images_path/'I1PD96856',\n",
    "    config.kangyur_opf,\n",
    "    index_layer,\n",
    "    start=19,\n",
    "    end=749,\n",
    "    replace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split('་'))\n",
    "    b = set(str2.split('་'))\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = '༄༅༅། །རྒྱ་གར་སྐད་དུ། ཡོ་ག་རཏྣ་མཱ་ལ་ནཱ་མ་ཧེ་བཛྲ་པཉྩི་ཀཱ། བོད་སྐད་དུ། དགྱེས་པ་རྡོ་རྗེའི་དཀའ་འགྲེལ་རྣལ་འབྱོར་རིན་པོ་ཆེའི་ཕྲེང་བ་ཞེས་བྱ་བ། དཔལ་དགྱེས་པའི་རྡོ་རྗེ་ལ་ཕྱག་'\n",
    "str2 = '༄༅༅། །རྒྱ་གར་སྐད་དུ། ཡོ་ག་རཏྣ་མཱ་ལ་ནཱ་མ་ཧེ་པཉྩི་ཀཱ། བོད་སྐད་དུ། དགྱེས་པ་རྡོ་རྗེའི་དཀའ་རྣལ་འབྱོར་རིན་ངག་གི་དབང་ཕྱུག་པོ་ཆེའི་ཕྲེང་བ་ཞེས་བྱ་བ། དཔལ་དགྱེས་པའི་རྡོ་རྗེ་ལ་ཕྱག་'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "str3 = '༄༅༅། །རྒྱ་གར་སྐད་དུ། ཧེ་བཛྲ་ཏནྟྲ་པཉྫི་ཀཱ་པདྨ་ནི་ནཱ་མ། བོད་སྐད་དུ། ཀྱེའི་རྡོ་རྗེའི་རྒྱུད་ཀྱི་དཀའ་འགྲེལ་པདྨ་ཅན་ཞེས་བྱ་བ། ངག་གི་དབང་ཕྱུག་འཇམ་དཔལ་གཞོན་ནུར་གྱུར་པ་ལ་ཕྱག་འཚལ་ལོ།'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_jaccard_sim(str1, str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_jaccard_sim(str1, str3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
